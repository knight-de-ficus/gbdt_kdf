import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# from IPython.core.display import display, HTML
import plotly.graph_objects as go

from sklearn.feature_selection import SelectKBest, chi2

def input_pd(filepath):
    """
    Read a CSV file and return a DataFrame.
    """
    df = pd.read_csv(filepath)
    return df

if __name__ == "__main__":
    
    df1 = pd.read_csv('./data_3/kddtrain_f.csv')
    df2 = pd.read_csv('./data_3/kddtrain_onehot.csv')

    
    train_df, test_df = feature_select.select_features(train_df, test_df, keep_ratio=0.5, save_path="selected_features_gbdt.png")


if __name__ == "__main1__":


    df = pd.read_csv('./data_3/kddtrain_f.csv')
    # df.info()
    # print(df.head(2))

    # df.describe(include='all')

    # list_drop = ['id','attack_cat']
    # df.drop(list_drop,axis=1,inplace=True)

    # df_numeric = df.select_dtypes(include=[np.number])
    # df_numeric.describe(include='all')


    # DEBUG =0
    # for feature in df_numeric.columns:
    #     if DEBUG == 1:
    #         print(feature)
    #         print('max = '+str(df_numeric[feature].max()))
    #         print('75th = '+str(df_numeric[feature].quantile(0.95)))
    #         print('median = '+str(df_numeric[feature].median()))
    #         print(df_numeric[feature].max()>10*df_numeric[feature].median())
    #         print('----------------------------------------------------')
    #     if df_numeric[feature].max()>10*df_numeric[feature].median() and df_numeric[feature].max()>10 :
    #         df[feature] = np.where(df[feature]<df[feature].quantile(0.95), df[feature], df[feature].quantile(0.95))

    # df_numeric = df.select_dtypes(include=[np.number])
    # df_numeric.describe(include='all')


    # df_numeric = df.select_dtypes(include=[np.number])
    # df_before = df_numeric.copy()
    # DEBUG = 0
    # for feature in df_numeric.columns:
    #     if DEBUG == 1:
    #         print(feature)
    #         print('nunique = '+str(df_numeric[feature].nunique()))
    #         print(df_numeric[feature].nunique()>50)
    #         print('----------------------------------------------------')
    #     if df_numeric[feature].nunique()>50:
    #         if df_numeric[feature].min()==0:
    #             df[feature] = np.log(df[feature]+1)
    #         else:
    #             df[feature] = np.log(df[feature])

    # df_numeric = df.select_dtypes(include=[np.number])


    # df_cat = df.select_dtypes(exclude=[np.number])
    # df_cat.describe(include='all')


    # DEBUG = 0
    # for feature in df_cat.columns:
    #     if DEBUG == 1:
    #         print(feature)
    #         print('nunique = '+str(df_cat[feature].nunique()))
    #         print(df_cat[feature].nunique()>6)
    #         print(sum(df[feature].isin(df[feature].value_counts().head().index)))
    #         print('----------------------------------------------------')
        
    #     if df_cat[feature].nunique()>6:
    #         df[feature] = np.where(df[feature].isin(df[feature].value_counts().head().index), df[feature], '-')


    # df_cat = df.select_dtypes(exclude=[np.number])
    # df_cat.describe(include='all')

    # df['proto'].value_counts().head().index
    # df['proto'].value_counts().index


    best_features = SelectKBest(score_func=chi2,k='all')

    X = df.iloc[:,1:-2]
    y = df.iloc[:,-1]
    fit = best_features.fit(X,y)

    df_scores=pd.DataFrame(fit.scores_)
    df_col=pd.DataFrame(X.columns)

    feature_score=pd.concat([df_col,df_scores],axis=1)
    feature_score.columns=['feature','score']
    feature_score.sort_values(by=['score'],ascending=True,inplace=True)

    fig = go.Figure(go.Bar(
                x=feature_score['score'][0:21],
                y=feature_score['feature'][0:21],
                orientation='h'))

    fig.update_layout(title="Top 20 Features",
                      height=1200,
                      showlegend=False,
                     )

    fig.show()

    # X = df.iloc[:,:-1]
    # y = df.iloc[:,-1]

    # X.head()
    # feature_names = list(X.columns)
    # np.shape(X)

    # from sklearn.compose import ColumnTransformer
    # from sklearn.preprocessing import OneHotEncoder
    # ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1,2,3])], remainder='passthrough')
    # X = np.array(ct.fit_transform(X))
    # np.shape(X)

    # for label in list(df_cat['state'].value_counts().index)[::-1][1:]:
    #     feature_names.insert(0,label)
        
    # for label in list(df_cat['service'].value_counts().index)[::-1][1:]:
    #     feature_names.insert(0,label)
        
    # for label in list(df_cat['proto'].value_counts().index)[::-1][1:]:
    #     feature_names.insert(0,label)

    # from sklearn.model_selection import train_test_split
    # X_train, X_test, y_train, y_test = train_test_split(X, y, 
    #                                                     test_size = 0.2, 
    #                                                     random_state = 0,
    #                                                     stratify=y)

    # from sklearn.preprocessing import StandardScaler
    # sc = StandardScaler()
    # X_train[:, 18:] = sc.fit_transform(X_train[:, 18:])
    # X_test[:, 18:] = sc.transform(X_test[:, 18:])

    # from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score
    # from sklearn.metrics import ConfusionMatrixDisplay # will plot the confusion matrix

    # import time
    # model_performance = pd.DataFrame(columns=['Accuracy','Recall','Precision','F1-Score','time to train','time to predict','total time'])

    # from sklearn.ensemble import GradientBoostingClassifier
    # start = time.time()
    # model = GradientBoostingClassifier().fit(X_train,y_train)
    # end_train = time.time()
    # y_predictions = model.predict(X_test) # These are the predictions from the test data.
    # end_predict = time.time()


    # accuracy = accuracy_score(y_test, y_predictions)
    # recall = recall_score(y_test, y_predictions, average='weighted')
    # precision = precision_score(y_test, y_predictions, average='weighted')
    # f1s = f1_score(y_test, y_predictions, average='weighted')

    # print("Accuracy: "+ "{:.2%}".format(accuracy))
    # print("Recall: "+ "{:.2%}".format(recall))
    # print("Precision: "+ "{:.2%}".format(precision))
    # print("F1-Score: "+ "{:.2%}".format(f1s))
    # print("time to train: "+ "{:.2f}".format(end_train-start)+" s")
    # print("time to predict: "+"{:.2f}".format(end_predict-end_train)+" s")
    # print("total: "+"{:.2f}".format(end_predict-start)+" s")
    # model_performance.loc['Gradient Boosting Classifier'] = [accuracy, recall, precision, f1s,end_train-start,end_predict-end_train,end_predict-start]
